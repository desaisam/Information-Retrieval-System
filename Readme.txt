This project contains below folders:  
Preprocessing : This folder has all the necessary programs to clean the query and corpus with / without stemming/ stop
Task1      : This folder contains programs and baseline runs for Task1 (TFIDF, QLM, BM25, Lucene)
Task2      : This folder contains the programs and results for query enhancements
Task3/RUN1 : This folder contains the programs and results  for Run1 , removing stopping words
Task3/RUN2 : This folder contains the programs and results for Run2, with stemming 
Phase2 : This folder contains the programs and results for Phase2 task i.e Snippet Generation 
Phase3 : This folder contains the programs and results for Phase3 i.e. Evaluation
==============================================================================================================================

preprocessing :
Download and install Beautiful Soup, NLTK.
CLEAN_CORPUS : The clean corpus after parsing HTML documents
RAW_HTML : The corpus given to us 
STEM_CORPUS : The corpus after performing stemming 
STOP_CORPUS : The corpus after removing the stop words 
cacm.query : Given query 
Clean_Query : Parsing cacm.query 
common_words : List of common stop words 
Generate_Clean_Corpus.py : This program generates the clean corpus - The folder CLEAN_CORPUS
Generate_Clean_Query.py : This program generats the clean query -- Clean_Query.txt
Generate_Stemmed_Corpus.py : This program generates the STEM_CORPUS folder which has all the stemmed version of corpus
Query_Without_Stop_Words : This text file contains the query after removing the stop words 
Query_Without_Stop_Words_lu : This text file contains the same data as above but formatted for luecne 
RemoveStopWords.py : This program removes the stop words from Corpus and Query
==============================================================================================================================
Task1:
task1.py : Implementation of the retrieval models - TFIDF, QLM (JM smoothing) and BM25
Parser.py : Implementation of parsing corpus to tokenize it into text files
Indexer.py : Implementation of Inverted Index that is referred to in task1.py.
Process:
1. Ensure cacm.rel, cacm.query and cacm corpus folder are all in the same place as the above three files. 
2. Ensure bs4 is imported.
3. Run task1.py and follow console prompts.
4. To run the Lucene implementation, create new project, add Lucene jars:
                   i.   lucene-core-VERSION.jar
                   ii.  lucene-queryparser-VERSION.jar
                   iii. lucene-analyzers-common-VERSION.jar
5. Update 'input location and queryReader' in Lucene.java as per actual locations of files/folders.
6. Run the Lucene.java file. Output is stored in "Lucene_scores.txt" file.
==============================================================================================================================
Task2 :
pseudo_relevance_feedback.py : Implementation of pseudo relevance feedback.
query_time_stemming.py : Implementation of query time stemming.
pseudo_relevance_feedback_results.txt : Top 100 results of pseudo relevance feedback.
query_time_stemming_results.txt : Top 100 results of query time stemming.
==============================================================================================================================
Task3/RUN1 :
BM25_Scores : The text file contains the top 100 results of BM25 calculation 
BM25_Stop.py : This program retrives the query using BM25  model. 	Please make sure you have the folder STOP_CORPUS, files : cacm.rel,Query_Without_Stop_Words.txt. Please copy form 
PREP folder 
Lucene_Stop.java : This gives the top 100 retrieval of Lucene implementation.
No_of_terms : Contains number of terms in each file .Generated by BM25_Stop.py 
Unigram : This is the inverted index. Generated by BM25_Stop.py
Unigram_df : This contains inverted index along with the information  about document frequency
==============================================================================================================================
Task3/RUN2: 
BM25_Scores_Stem : The text file contains the top 100 results of BM25 calculation after performing stemming  	
BM25_Stop.py : This program retrives the query using BM25  model. 	Please make sure you have the folder STEM_CORPUS, files : cacm.rel,cacm_stem,.query.txt. Please copy form 
PREP folder 
HW4.java : This gives the top 100 retrieval of Lucene implementation perfomed on stemmed corpus.
No_of_terms_Stem : Contains number of terms in each file .Generated by BM25_Stop.py 
Unigram_Stem : This is the inverted index. Generated by BM25_Stop.py perfomed on stemmed corpus
LUCENE_Results_Stem : This gives the top 100 retrieval of Lucene implementation.
Unigram_df_Stem : This contains inverted index along with the information  about document frequency perfomed on stemmed corpus
cacm_stem.query.txt : The stemmed query given .
==============================================================================================================================


Please run in the following order ONLY : 
1) Generate_Clean_Corpus.py
2) Generate_Clean_Query.py
3) Generate_Stemmed_Corpus.py
4) BM25_Stop.py
5) Lucene_Stop.java
6) BM25_Stop.py
7) HW4.java

**** PLEASE MAKE SURE THAT ALL THE REQUISITE FOLDER AND FILES ARE PRESENT IN THE RESPECTIVE FOLDERS BEFORE RUNNING THE PROGRAM*******
==============================================================================================================================
Phase 2 :
This folder contains :
RAW_HTML : The corpus
Snippets : The Snippets for the Queries in the file Clean_Query.txt
Clean_Query.txt : This file contains the the queries parsed from cacm.query
common_words : Set of common words
Unigram.txt : The inverted index from Phase 3. Pasted here again to make this run independent of task 3
SnippetGeneration.py : Source code which generates the snippets.

Run the program SnippetGeneration.py by making sure you have all the necessay files and folder(mentioned above except the output folder) in the current working directory.
Running this program should produce a folder Snippets which should have all the snippets from the 64 given queries.
==============================================================================================================================
Phase 3:
pseudo_relevance_feedback_with_bm25.py: This program is the ninth retrieval model that uses a different retrieval engine than before (bm25 as opposed to tf-idf) and query expansion, namely pseudo-relevance feedback. The results are in the similarly named txt file.
map.py: Generates the MAP scores for all result files and puts them in map_scores.txt
mrr.py: Generates the MRR scores for all result files and puts them in mrr_scores.txt
get_result_information.py: Utility file to parse and retrieve the result files.
metrics.py: Generates the P@K and Precision and Recall values for all result files. The file "RunType.txt" must be changed to include the path to the results file for which evaluation must be run. Scores are output in files with the following naming convention - <RetrievalSystem>+"Metrics.txt" (i.e. "BM25Metrics.txt etc). In this repository, the Phase3/Metrics/" path holds the outputs of the nine resulting runs from all previous tasks.
==============================================================================================================================
Extra Credit:
extra_credit.py: Does spelling correction for all queries in Clean_Queries.txt and outputs the corrected queries in corrected_queries.txt
